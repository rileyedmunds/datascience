{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis is a simple classifation algorithm, supervised.\\n\\nTERMS:\\nmargin := distance between plane and two closest datapoints from each class\\nsvm:= the points that define the margin are called support vectors, since they 'support' and define the hyperplane. thus, support vector machine\\n\\n\\nThe idea: perform kernel trick to project data into higher dimensions, then splitting it with a hyperplane\\n\\nexample: red and blue balls on table separated by stick (1-dim hyperplane)\\n    kernel trick here: throw balls off table and while in mid air (third dimension), separate them with paper (2-dim hyperplane)\\n\\n\\nClassification:\\n    train SVM with data, then hyperplane tells you class of data depending on which side new data lies.\\n\\nKernels:\\n    linear (when # features > # observations because typically linearly independent)\\n    polynomial\\n    gaussian rbf\\n    tanh\\n    \\nMath: using quadratic programming to solve for coefficients of minimization and maximization problem\\n    \\nNote: nonlinear kernels good when need better mapping. at least as good as linear!\\n\\nBest approach: choose many kernels and cross-validate!!!\\n    \\n    \\n    \\n    \\nSupport vector regression vs Support vector classification:\\nSVR: outputs ordinals (numbers)\\nSVC: outputs categorical data (classes)\\n\\nDiscrete data: can use classification or regression\\nContinuous data: can use classification of regression\\n\\nRegression vs Classification:\\nwe choose one or the other based on whether our desired ouputs are ordinal in nature, or categorial in nature\\nex. classify flowers --> categorical (lily /> rose)\\nex. predict price --> ordinal (difference between 50 and 15 is not same as distance between 50 and 49)\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "'''\n",
    "This is a simple classifation algorithm, supervised.\n",
    "Minimizes margin to learn best fit hyperplane! (dividing line)\n",
    "\n",
    "TERMS:\n",
    "margin := distance between plane and two closest datapoints from each class\n",
    "svm:= the points that define the margin are called support vectors, since they 'support' and define the hyperplane. thus, support vector machine\n",
    "\n",
    "\n",
    "The idea: perform kernel trick to project data into higher dimensions, then splitting it with a hyperplane\n",
    "\n",
    "\n",
    "example: red and blue balls on table separated by stick (1-dim hyperplane)\n",
    "    kernel trick here: throw balls off table and while in mid air (third dimension), separate them with paper (2-dim hyperplane)\n",
    "\n",
    "\n",
    "Classification:\n",
    "    train SVM with data, then hyperplane tells you class of data depending on which side new data lies.\n",
    "\n",
    "Kernels:\n",
    "    linear (when # features > # observations because typically linearly independent)\n",
    "    polynomial\n",
    "    gaussian rbf\n",
    "    tanh\n",
    "    \n",
    "Math: using quadratic programming to solve for coefficients of minimization and maximization problem\n",
    "    \n",
    "Note: nonlinear kernels good when need better mapping. at least as good as linear!\n",
    "\n",
    "Best approach: choose many kernels and cross-validate!!!\n",
    "    \n",
    "    \n",
    "Support vector regression vs Support vector classification:\n",
    "SVR: outputs ordinals (numbers)\n",
    "    for this, the number output is on the line\n",
    "SVC: outputs categorical data (classes) (nominal data == name data == categorical data)\n",
    "\n",
    "Discrete data: can use classification or regression\n",
    "Continuous data: can use classification of regression\n",
    "\n",
    "Regression vs Classification:\n",
    "we choose one or the other based on whether our desired ouputs are ordinal in nature, or categorial in nature\n",
    "ex. classify flowers --> categorical (lily /> rose)\n",
    "ex. predict price --> ordinal (difference between 50 and 15 is not same as distance between 50 and 49)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Simple implementation in sklearn of SVC \n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loading in data from iris dataset\n",
    "iris = datasets.load_iris()\n",
    "# X, y = iris.data, iris.target\n",
    "X,y = {},{}\n",
    "X['train'] = iris.data[:120]\n",
    "X['test'] = iris.data[120:]\n",
    "y['train'] = iris.target[:120]\n",
    "y['test'] = iris.target[120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating classifier\n",
    "clf_rbf = svm.SVC(kernel=\"rbf\")\n",
    "clf_rbf.fit(X['train'], y['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testing function\n",
    "def test(clf, data, label):\n",
    "    '''returns accuracy on test set'''\n",
    "    bool_equal = clf.predict(data) == label\n",
    "    return np.count_nonzero(bool_equal) / len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(clf_rbf, X['test'], y['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating classifier\n",
    "clf_linear = svm.SVC(kernel=\"rbf\")\n",
    "clf_linear.fit(X['train'], y['train'])\n",
    "\n",
    "#creating classifier\n",
    "clf_linear = svm.SVC(kernel=\"rbf\")\n",
    "clf_linear.fit(X['train'], y['train'])\n",
    "\n",
    "#creating classifier\n",
    "clf_poly = svm.SVC(kernel=\"poly\")\n",
    "clf_poly.fit(X['train'], y['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334  =rbf\n",
      "0.8333333333333334  =linear\n",
      "0.7666666666666667  =poly\n"
     ]
    }
   ],
   "source": [
    "print(test(clf_rbf, X['test'], y['test']), \" =rbf\")\n",
    "print(test(clf_linear, X['test'], y['test']), \" =linear\")\n",
    "print(test(clf_poly, X['test'], y['test']), \" =poly\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
